{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML exam, теория"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи классификации\n",
    "\n",
    "Пусть $X$ --- множество объектов, $Y$ --- множество ответов, $y:X\\to Y$ --- неизвестная зависимость. \n",
    "\n",
    "Дано: обучающая выборка --- $\\mathsf{(x_1,\\ldots, x_n) \\subset X}$, $\\mathsf{y_i=y(x_i), ~i=1,\\ldots,n}$ --- известные ответы. \n",
    "\n",
    "Найти: $\\mathsf{a:X\\to Y}$ --- функцию (decision function), приближающую $\\mathsf{y}$ на всем множестве $\\mathsf{X}$. \n",
    "   \n",
    "Вероятностная постановка задачи: имеется неизвестное распределение на множестве $\\mathsf{X\\times Y}$ с плотностью $\\mathsf{p(x,y)}$, из которого случайно выбираются $\\mathbb{X}_\\mathsf{n}=\\mathsf{(x_i,y_i)_{i=1}^n}$ (независимые). \n",
    "\n",
    "Задача классификации: \n",
    " \n",
    " $\\mathsf{Y}=\\{-1,+1\\}$ --- классификация на 2 класса\n",
    " \n",
    " $\\mathsf{Y}=\\{1,\\ldots,K\\}$ --- классификация на $K$ классов\n",
    "\n",
    "Классификатор будем строить $a(x,w) = \\text{sign}~ f(x,w)$, где $f(x,w)$ --- разделяющая функция.\n",
    "$\\mathsf{M_i(w)=y_if(x_i,w)}$ --- отступ объекта $\\mathsf{x_i}$. \n",
    "\n",
    "Задача: минимизировать число ошибок классификации (отрицательных отступов)\n",
    "$$ Q(\\mathsf{w)=\\sum \\limits_{i=1}^n [M_i(w)<0]}\\le \\tilde Q(\\mathsf{w)=\\sum \\limits_{i=1}^n \\mathcal{L}(M_i(w)) \\to \\min \\limits_{w}}$$\n",
    "\n",
    "Линейный классификатор: $\\mathsf{a(x,w)=\\text{sign}~ (\\sum\\limits_{j=1}^pw_jf_j(x)-w_0),~~~w_0,w_1,\\ldots,w_p\\in\\mathbb{R}}$.\n",
    "\n",
    "Пусть $\\mathsf{f_0=-1}$, тогда\n",
    "\n",
    " $$\\mathsf{a(x,w)=\\text{sign}~\\langle w,x\\rangle ,~ x,w\\in\\mathbb{R}^{p+1}}.$$\n",
    " \n",
    " \n",
    " $\\mathsf{M_i(x)=y_i\\langle w,x_i\\rangle}$ --- отступ объекта $\\mathsf{x_i}$. \n",
    " \n",
    "Задача: $$\\mathsf{Q(w)=\\sum \\limits_{i=1}^n [y_i\\langle w,x_i\\rangle <0] \\le \\sum \\limits_{i=1}^n \\mathcal{L}(y_i\\langle w,x_i\\rangle) \\to \\min \\limits_{w}}$$\n",
    "\n",
    "\n",
    "# Логистическая регрессия.\n",
    "\n",
    "2 эквивалентных подхода: через функцию риска и через модель для вероятности в распределении Бернулли.\n",
    "\n",
    "### 1 подход (минимизация функции потерь)\n",
    "\n",
    "Линейная модель классификации: $\\mathsf{a(x)=\\text{sign}~ \\langle w,x\\rangle,~~~ x,w\\in \\mathbb{R}^p,~~ M=\\langle w,x \\rangle y}$ --- отступ. \n",
    "\n",
    "В качестве аппроксимации пороговой функции потерь берется логарифмическая функция потерь $\\mathcal{L}(\\mathsf{M})=\\log(1+e^{-\\mathsf{M}})$ и задача выглядит следующим образом: \n",
    "$$\\mathsf{Q(w)=\\sum \\limits_{i=1}^n \\log (1+\\exp{(-y_i\\langle w,x_i\\rangle)}) \\to \\min \\limits_{w}}.$$\n",
    "\n",
    "Способы решения задачи минимизации: метод стохастического градиента, метод Ньютона-Рафсона.\n",
    "\n",
    "### 2 подход (вероятностный подход)\n",
    "\n",
    "Хотим оценить вероятности принадлежности какому-то классу.\n",
    "\n",
    "Пусть $Y =\\{0,1\\}.$ Пусть $P(y=1|x) = \\frac{e^{w_0+w_1x_1+\\ldots+w_px_p}}{1+e^{w_0+w_1x_1+\\ldots+w_px_p}} = \\sigma_w(x).$ (Делается предположение о том, что вероятность наступления события y=1 такова) \n",
    "\n",
    "($f(z) = \\frac{1}{1+e^{-z}}$ --- сигмоидная функция.)\n",
    "\n",
    "Тогда вероятность принять значение 0 равна: $P(y=0)=1-\\sigma_w(x).$\n",
    "\n",
    "Тогда $\\mathsf{P(y|x;w)=(\\sigma_w(x))^y(1-\\sigma_w(x))^{1-y}}.$\n",
    "\n",
    "Фактически, это есть распределение Бернулли с параметром, равным $\\sigma_w(x).$\n",
    "\n",
    "Выписываем функцию правдоподобия: \n",
    "$$\\mathsf{Q(w)=-\\log L(w)=-\\log \\prod\\limits_{i=1}^n(\\sigma_w(x_i))^{y_i}(1-\\sigma_w(x_i))^{1-y_i}}= =\\mathsf{-\\sum\\limits_{i=1}^n [y_i\\log (\\sigma_w(x_i)+(1-y_i))\\log (1-\\sigma_w(x_i))]\\to \\min\\limits_{w}} $$\n",
    "\n",
    "Если несколько классов, $Y=\\{1,\\ldots,K\\}.$ Тогда линейный классификатор: $\\mathsf{a(x,w)=\\text{argmax}_{y\\in Y}\\langle w_y,x \\rangle,~~~x,w_y\\in\\mathbb{R}^p },$\n",
    "\n",
    "Вероятность того, что объект $\\mathsf{x}$ относится к классу $\\mathsf{i}$:\n",
    "\t$\\mathsf{P(y=i|x;w)=\\frac{\\exp{\\langle w_y,x \\rangle}}{\\sum\\limits_{z\\in Y}\\exp{\\langle w_z,x \\rangle}}=\\frac{e^{w_i^{\\mathrm{T}}x}}{\\sum\\limits_{k=1}^Ke^{w_k^{\\mathrm{T}}x}} }.$\n",
    "    \n",
    "Задача:\t$\\mathsf{Q(w)=-\\sum\\limits_{i=1}^n\\log P(y_i|x_i;w)\\to \\min\\limits_w }$\n",
    "\t\n",
    "\n",
    "### Задача с регуляризацией: \n",
    "\n",
    "$$Q(\\mathsf{w;\\mathbb{X}_n)=\\sum\\limits_{i=1}^n \\ln p(x_i,y_i|w)+\\frac{1}{C}\\sum\\limits_{j=1}^pw_j^2 \\to \\min\\limits_{w,C}}  ~~~(L2~ регуляризация)$$\n",
    "$$Q(\\mathsf{w;\\mathbb{X}_n)=\\sum\\limits_{i=1}^n \\ln p(x_i,y_i|w)+\\frac{1}{C}\\sum\\limits_{j=1}^p|w_j| \\to \\min\\limits_{w,C}} ~~~ (L1~ регуляризация)$$\n",
    "\n",
    "При уменьшении $C$ регуляризация сильнее. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция в python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class sklearn.linear_model.LogisticRegression(penalty='l2',   dual=False,   tol=0.0001,   C=1.0,   fit_intercept=True, intercept_scaling=1,   class_weight=None,   random_state=None,   solver='lbfgs',   max_iter=100,   multi_class='auto', verbose=0,   warm_start=False,   n_jobs=None,   l1_ratio=None)\n",
    "\n",
    "\n",
    "In the multiclass case, the training algorithm uses the one-vs-rest (OvR) scheme if the ‘multi_class’ option is set to ‘ovr’, and uses the cross-entropy loss if the ‘multi_class’ option is set to ‘multinomial’. (Currently the ‘multinomial’ option is supported only by the ‘lbfgs’, ‘sag’, ‘saga’ and ‘newton-cg’ solvers.)\n",
    "\n",
    "This class implements regularized logistic regression using the ‘liblinear’ library, ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ solvers. Note that regularization is applied by default. It can handle both dense and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit floats for optimal performance; any other input format will be converted (and copied).\n",
    "\n",
    "The ‘newton-cg’, ‘sag’, and ‘lbfgs’ solvers support only L2 regularization with primal formulation, or no regularization. The ‘liblinear’ solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty. The Elastic-Net regularization is only supported by the ‘saga’ solver.\n",
    "\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- penalty: {‘l1’, ‘l2’}, default=’l2’ --- вид регуляризации, “lbfgs”и “newton-cg” поддреживают только L2 регуляризвцию.\n",
    "\n",
    "\n",
    "- dual: bool, default=False --- прямая или дуальная задача оптимизации. Дуальная формулировка поддерживается только с liblinear. Лучше использовать dual=False, когдаn_samples>n_features.\n",
    "\n",
    "\n",
    "- tol: float, default=1e-4 --- Tolerance for stopping criteria.\n",
    "\n",
    "\n",
    "- C: float, default=1.0 --- параметр регуляризации (inverse of regularization strength), должен быть положительным float. Меньшее С обеспечивает более сильную регуляризацию.\n",
    "\n",
    "\n",
    "- fit_intercept: bool, default=True --- определяет добавлять ли константу к решающей функции.\n",
    "\n",
    "\n",
    "- intercept_scaling: float, default=1 --- Useful only when the solver ‘liblinear’ is used and self.fit_intercept is set to True. In this case, x becomes [x, self.intercept_scaling], i.e. a “synthetic” feature with constant value equal to intercept_scaling is appended to the instance vector. The intercept becomes intercept_scaling * synthetic_feature_weight.\n",
    "\n",
    "\n",
    "- class_weight: dict or ‘balanced’, default=None --- Weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one. The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)). Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified.\n",
    "\n",
    "\n",
    "- random_state: int, RandomState instance, default=None \n",
    "\n",
    "- solver: {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’ --- Algorithm to use in the optimization problem.\n",
    "\n",
    "For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
    "\n",
    "For multiclass problems, only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ handle multinomial loss; ‘liblinear’ is limited to one-versus-rest schemes.\n",
    "\n",
    "‘newton-cg’, ‘lbfgs’, ‘sag’ and ‘saga’ handle L2 or no penalty\n",
    "\n",
    "‘liblinear’ and ‘saga’ also handle L1 penalty\n",
    "\n",
    "‘saga’ also supports ‘elasticnet’ penalty\n",
    "\n",
    "‘liblinear’ does not support setting penalty='none'\n",
    "\n",
    "Note that ‘sag’ and ‘saga’ fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing.\n",
    "\n",
    "\n",
    "- max_iter: int, default=100 --- Maximum number of iterations taken for the solvers to converge.\n",
    "\n",
    "\n",
    "- multi_class: {‘auto’, ‘ovr’, ‘multinomial’}, default=’auto’\n",
    "If the option chosen is ‘ovr’, then a binary problem is fit for each label. For ‘multinomial’ the loss minimised is the multinomial loss fit across the entire probability distribution, even when the data is binary. ‘multinomial’ is unavailable when solver=’liblinear’. ‘auto’ selects ‘ovr’ if the data is binary, or if solver=’liblinear’, and otherwise selects ‘multinomial’.\n",
    "\n",
    "\n",
    "- verbose: int, default=0\n",
    "For the liblinear and lbfgs solvers set verbose to any positive number for verbosity.\n",
    "\n",
    "\n",
    "- warm_start: bool, default=False\n",
    "When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. Useless for liblinear solver. See the Glossary.\n",
    "\n",
    "\n",
    "- n_jobs: int, default=None\n",
    "Number of CPU cores used when parallelizing over classes if multi_class=’ovr’”. This parameter is ignored when the solver is set to ‘liblinear’ regardless of whether ‘multi_class’ is specified or not. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.\n",
    "\n",
    "\n",
    "- l1_ratio: float, default=None --- The Elastic-Net mixing parameter, with 0 <= l1_ratio <= 1. Only used if penalty='elasticnet'. Setting 'l1_ratio=0 is equivalent to using penalty='l2', while setting l1_ratio=1 is equivalent to using penalty='l1'. For 0 < l1_ratio <1, the penalty is a combination of L1 and L2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последовательное обучение базовых алгоритмов; каждый следующий исправляет ошибки предыдущих; за счет этого достаточно простых базовых алгоритмов. \n",
    "\n",
    "Постановка задачи:\n",
    "\n",
    "Пусть $X$ --- множество объектов, $Y$ --- множество ответов\n",
    "$y: X \\to Y$ --- неизвестная зависимость.\n",
    "\n",
    "Дано: обучающая выборка --- $X^n = (x_i,y_i)_{i=1}^n $, $y_i = y(x_i), i = 1,\\ldots,n$ --- известные ответы.\n",
    "\n",
    "Требуется построить алгоритм $a(x) = C(b(x))$, аппроксимирующий целевую зависимость $y$ на всём множестве $X$.\n",
    "\n",
    "$b: X\\to R$ --- базовый алгоритм, $C: R\\to Y$ --- рещающее правило, $R$ --- пространство оценок. (Сначала оцениваем степень принадлежности объекта классу, а затем решаем, к какому классу его отнести. \n",
    "\n",
    "Изменение постановки задачи: вместо одного базового алгоритма $b$ рассматривается несколько алгоритмов $b_1(x), \\ldots , b_T (x)$. И строим композицию базовых алгоритмов $a(x)=C(F(b_1(x),\\ldots,b_T(x))),$ где $F:R^T\\to R$ --- корректирующая операция. (Пространство оценок R вводится для того, чтобы расширить множество допустимых корректирующих операций)\n",
    "\n",
    "В качестве базовых алгоритмов обычно выступают:\n",
    "   решающие деревья (неглубокие 2-8) — используются чаще всего;\n",
    "   пороговые правила (data stumps).\n",
    "\n",
    "Примеры корректирующих операций:\n",
    "\n",
    " - Простое голосование (Simple Voting):\n",
    "$$F(b_1(x), \\ldots , b_T(x))= \\frac{1}{T} \\sum_{t=1}^{T} b_t(x), \\quad x \\in X.$$\n",
    "\n",
    " - Взвешенное голосование (Weighted Voting):\n",
    "$$F(b_1(x), \\ldots , b_T(x))= \\sum_{t=1}^{T} \\alpha_t b_t(x), \\quad x \\in X, \\quad \\alpha_t \\in R.$$\n",
    "\n",
    " - Смесь алгоритмов (Mixture of Experts):\n",
    "$$F(b_1(x), \\ldots , b_T(x))= \\sum_{t=1}^{T} g_t(x)b_t(x), \\quad x \\in X, \\quad g_t: X \\to  \\mathbb R.$$  \n",
    "\n",
    "\n",
    "Последовательное обучение:\n",
    "Хотим минимизировать функцию потерь, \n",
    "$$Q(b,X^n) = \\sum \\limits_{i=1}^n \\mathcal{L}(b(x_i),y_i).$$\n",
    "\n",
    "Итерации: \n",
    "   - обучим простой алгоритм: $b_1(x) = \\arg \\min \\limits_{b \\in \\mathcal{B}} Q(b,X^n)$;\n",
    "   \n",
    "   - хотим добавить еще один алгоритм:  $b_2(x) = \\arg \\min \\limits_{b,F} Q(F(b_1,b),X^n) $ \n",
    "   - $\\ldots$ \n",
    "   - $b_T(x) = \\arg \\min \\limits_{b,F} Q(F(b_1,\\ldots,b_{T-1},b),X^n)$\n",
    "   \n",
    "  Такие задачи решать неудобно, и утверждается, что задачу можно свести к следующей: $b_t = \\arg \\min \\limits_{b} \\sum \\limits_{i=1}^n w_i \\tilde{\\mathcal{L}}(b(x_i),y_i).$\n",
    "  \n",
    "  ### Adaboost\n",
    "  \n",
    "  Пусть $Y=\\{-1,+1\\},~ C(b) = sign(b),~ b_t:X\\to \\{-1,0,1\\}$ (имеются отказы). Композиция имеет вид $$ a(x) = C(F(b_1(x),\\ldots, b_T(x)) = sign (\\sum\\limits_{t=1}^T \\alpha_t b_t(x)).$$\n",
    "  \n",
    "  Функционал качества ошибок классификации: $$Q_T = \\sum_{i=1}^{n} [y_i \\sum\\limits_{t=1}^T \\alpha_t b_t(x)<0].$$\n",
    "  Используется аппроксимация функции потерь: $e^{-M}.$\n",
    "  \n",
    "   $$Q_T \\leq \\widetilde {Q}_T =\\sum_{i=1}^{n} \\exp \\left(-y_i \\sum_{t=1}^{T} \\alpha_t b_t(x_i) \\right) =\n",
    " -\\sum_{i=1}^{n}  \\underbrace{\\exp \\left(-y_i \\sum_{t=1}^{T-1} \\alpha_t b_t(x_i) \\right)}_{\\omega_i} e^{−y_i\\alpha_T b_T(x_i)}$$\n",
    "\n",
    "\n",
    "Заметим, что введённые здесь веса объектов $\\omega_i$ не зависят от $\\alpha_T b_T$ и могут быть вычислены перед построением базового алгоритма $b_T$.\n",
    "\n",
    "Введём вектор нормированных весов $\\widetilde W^n = \\widetilde{\\omega}_1, \\ldots, \\widetilde{\\omega}_n$, где $\\widetilde{\\omega}_i = \\omega_i / \\sum_{j=1}^{n} \\omega_j$.\n",
    "\n",
    "\n",
    "Определим два функционала качества алгоритма классификации $b$ на обучающей выборке  $X^n = (x_i,y_i)_{i=1}^n$ с нормированным вектором весов объектов $U^n = (u_1, \\ldots , u_n)$: суммарный вес ошибочных (negative) классификаций $N(b; U^n)$ и суммарный вес правильных (positive) классификаций $P(b; U^n)$:\n",
    "$$N(b; U^n) = \\sum_{i=1}^{n} u_i [b(x_i)=-y_i],$$\n",
    "$$P(b; U^n) = \\sum_{i=1}^{n} u_i [b(x_i)=y_i].$$\n",
    "\n",
    "Заметим, что $1 - N - P$ есть суммарный вес отказов от классификации. Если отказов нет, то $N + P = 1$.   \n",
    "\n",
    "\n",
    "Основная теорема бустинга (для AdaBoost).\n",
    "Пусть $\\mathcal{B}$ --- достаточно богатое семейство базовых алгоритмов, то есть для любого нормированного вектора весов $U^n$ существует алгоритм $b \\in \\mathcal{B}$, классифицирующий выборку хотя бы немного лучше, чем наугад: $P(b; U^n)>N(b; U^n)$.\n",
    "\n",
    "Тогда минимум функционала $\\widetilde {Q}_T$ достигается при\n",
    "$$b_T = \\arg \\max \\limits_{b \\in \\mathcal{B}} \\sqrt{P(b; \\widetilde{W}^n)}-\\sqrt{N(b; \\widetilde {W}^n)},$$\n",
    "$$a_t = \\frac{1}{2} \\ln \\frac{P(b_t; \\widetilde{W}^n)}{N(b_t; \\widetilde{W}^n)}.$$\n",
    "\n",
    "Алгоритм Adaboost:\n",
    "\n",
    "Вход: $X^n = (x_i,y_i)_{i=1}^n$ - обучающая выборка, $T$ - максимальное число базовых алгоритмов.\n",
    "Выход: базовые алгоритмы и их веса $\\alpha_t b_t$, $t = 1, \\ldots, T$.\n",
    "\n",
    "1. инициализация весов объектов: $\\omega_i := 1/n$, $i = 1, \\ldots, n$;\n",
    "\n",
    "2. для всех $t=1,\\ldots,T$, пока не выполнен критерий остановки:\n",
    "\n",
    " a. обучить базовый алгоритм: $b_t := \\arg \\min \\limits_{b \\in \\mathcal{B}} N(b; W^n)$;\n",
    " \n",
    " b.  $\\alpha_t := \\frac{1}{2} \\ln \\frac{1-N(b_t; W^n)}{N(b_t; W^n)}$;\n",
    " \n",
    " c. пересчет весов объектов: $\\omega_i := \\omega_i e^{−\\alpha_t y_i b_t(x_i)}$, $i = 1, \\ldots, n$;\n",
    " \n",
    " d. нормировка весов объектов: $\\omega_0 := \\sum_{j=1}^{n} \\omega_j$; $\\omega_i:=\\omega_i/\\omega_0$, $i = 1, \\ldots, n$.\n",
    " \n",
    " ### Обобщение бустинга\n",
    " \n",
    " $$Q_T \\leq \\widetilde {Q}_T =\\sum_{i=1}^{n} \\mathcal{L} (M_{T-1}(x_i) + y_i \\alpha_T b_T(x_i)) \\to \\min \\limits_{\\alpha, b \\in \\mathcal{B}}.$$\n",
    " \n",
    " Линеаризуем $\\mathcal{L}$ в окресности $\\alpha = 0$,\n",
    "\n",
    "$$\\widetilde {Q}_T \\approx \\sum_{i=1}^{n} \\mathcal{L} (M_{T-1}(x_i)) - \\alpha \\sum_{i=1}^{n} \\underbrace{ - \\mathcal{L}' (M_{T-1}(x_i))}_{w_i} y_i b(x_i) \\to \\min \\limits_{b \\in \\mathcal{B}},$$\n",
    "где $w_i$ — веса объектов.\n",
    "\n",
    "Минимизация линеаризованного $\\widetilde {Q}_T$ при фиксированном $\\alpha$:\n",
    "$$\\widetilde {Q}_T \\approx \\sum_{i=1}^{n} \\mathcal{L} (M_{T-1}(x_i)) - \\alpha \\sum_{i=1}^{n} \\omega_i y_i b(x_i) \\to \\min \\limits_{b \\in \\mathcal{B}}$$\n",
    "приводит к принципу явной максимизации отступов (direct optimization of margin, DOOM):\n",
    "$$\\sum_{i=1}^{n} \\omega_i y_i b(x_i) \\to \\max \\limits_{b \\in \\mathcal{B}}.$$\n",
    "\n",
    "Затем $\\alpha$ определяется путём одномерной минимизации $\\widetilde {Q}_T$.\n",
    "\n",
    "Итерации этих двух шагов приводят к алгоритму AnyBoost.\n",
    "\n",
    "Вход: $X^n = (x_i,y_i)_{i=1}^n$ - обучающая выборка, $T$ - максимальное число базовых алгоритмов.\n",
    "Выход: базовые алгоритмы и их веса $\\alpha_t b_t$, $t = 1, \\ldots, T$.\n",
    "\n",
    "1. инициализация отступов: $M_i := 0$, $i = 1, \\ldots, n$;\n",
    "\n",
    "2. для всех $t=1,\\ldots,T$, пока не выполнен критерий остановки:\n",
    "\n",
    " a. вычислить веса объектов: $\\omega_i = -\\mathcal{L}'(M_i)$, $i = 1, \\ldots, n$;\n",
    " \n",
    " b. обучить базовый алгоритм согласно принципу DOOM: $b_t := \\arg \\max \\limits_{b \\in \\mathcal{B}} \\sum_{i=1}^{n} \\omega_i y_i b(x_i)$;\n",
    " \n",
    " c. решить задачу одномерной минимизации: $a_t := \\arg \\max \\limits_{\\alpha} \\sum_{i=1}^{n} \\mathcal{L} (M_i+\\alpha b_t(x_i) y_i)$;\n",
    " \n",
    " d. пересчет отступов: $M_i := M_i +\\alpha b_t(x_i) y_i$; $i = 1, \\ldots, n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции в python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost\n",
    "\n",
    "class sklearn.ensemble.AdaBoostClassifier(base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=None)\n",
    "\n",
    "An AdaBoost classifier is a meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases.\n",
    "\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- base_estimator: object, optional (default=None) --- базовый алгоритм. \n",
    "The base estimator from which the boosted ensemble is built. Support for sample weighting is required, as well as proper classes_ and n_classes_ attributes. If None, then the base estimator is DecisionTreeClassifier(max_depth=1).\n",
    "\n",
    "\n",
    "- n_estimators: int, optional (default=50) --- максимальное количество базовых алгоритмов. \n",
    "The maximum number of estimators at which boosting is terminated. In case of perfect fit, the learning procedure is stopped early.\n",
    "\n",
    "\n",
    "- learning_rate: float, optional (default=1.)\n",
    "Learning rate shrinks the contribution of each classifier by learning_rate. There is a trade-off between learning_rate and n_estimators.\n",
    "\n",
    "\n",
    "- algorithm{‘SAMME’, ‘SAMME.R’}, optional (default=’SAMME.R’)\n",
    "If ‘SAMME.R’ then use the SAMME.R real boosting algorithm. base_estimator must support calculation of class probabilities. If ‘SAMME’ then use the SAMME discrete boosting algorithm. The SAMME.R algorithm typically converges faster than SAMME, achieving a lower test error with fewer boosting iterations.\n",
    "\n",
    "\n",
    "- random_state: int, RandomState instance or None, optional (default=None)\n",
    "If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры\n",
    "\n",
    "Одна из самых популярных библиотек при работе с бустингом -- xgboost. Он реализует алгоритм градиентного бустинга в довольно общем виде.\n",
    "\n",
    "Рассмотрим параметры XGboost. Выделяют три группы параметров:\n",
    "\n",
    "- Общие параметры, отвечающие за базовый алгоритм для бустинга и распараллеливание.\n",
    "- Параметры выбранного базового алгоритма.\n",
    "- Параметры обучения, отвечающие за функцию потерь и метрику качества на валидации.\n",
    "\n",
    " Общие параметры:\n",
    " \n",
    "- booster - тип базового алгоритма для бустинга: дерево решений gbtree или линейная модель gblinear, dart.\n",
    "- silent(/verbosity) - выдавать (silent=0) или нет (silent=1) сообщения по ходу работы алгоритма. (Valid values are 0 (silent) - 3 (debug).)\n",
    "- nthread (/n_jobs)- число нитей доступных для параллельной работы xgboost.\n",
    "\n",
    "Параметры базового алгоритма:\n",
    "\n",
    "Дерево решений:\n",
    "- eta (/learning_rate) - темп обучения, перед добавлением дерева в композицию оно умножается на eta. Используется для предотвращения переобучения за счёт \"сокращения\" весов базовых алгоритмов, делая модель более консервативной. Чем меньше eta, тем больше нужно итераций num_boost_round для обучения модели с хорошим качеством. Диапазон: $[0, 1]$\n",
    "\n",
    "- gamma - минимальное снижение значения функции потерь, необходимое для дальнейшего разбиения вершины дерева. Большие значения gamma > 0 приводят к более консервативным моделям. Диапазон: $[0, \\infty)$.\n",
    "\n",
    "- max_depth - максимальная глубина дерева. Диапазон: [1, $\\infty$).\n",
    "\n",
    "- min_child_weight - минимальное необходимое (взвешенное) число примеров в каждой вершине. Чем больше, тем более консервативна итоговая модель. Диапазон: $[0, \\infty)$.\n",
    "\n",
    "- max_delta_step - обычно равен нулю. Положительные значения используются при несбалансированных классах для ускорения сходимости. Диапазон $[0, \\infty)$.\n",
    "\n",
    "- subsample - доля выборки, используемая для обучения каждого дерева. Если subsample < 1, то выбирается случайная подвыборка, что помогает в борьбе с переобучением. Диапазон: $(0, 1]$\n",
    "\n",
    "- colsample_bytree - доля признаков, используемая для обучения каждого дерева. Диапазон: $(0, 1]$\n",
    "\n",
    "- lambda (/reg_lambda) - коэффициент перед $L_2$-регуляризатором в функции потерь.\n",
    "\n",
    "- alpha (/reg_alpha) - коэффициент перед $L_1$-регуляризатором в функции потерь.\n",
    "\n",
    "Линейная модель:\n",
    "\n",
    "- lambda - коэффициент перед $L_2$-регуляризатором вектора весов в функции потерь.\n",
    "\n",
    "- alpha - коэффициент перед $L_1$-регуляризатором вектора весов в функции потерь.\n",
    "\n",
    "- lambda_bias - коэффициент перед $L_2$-регуляризатором смещения (свободного члена) в функции потерь.\n",
    "\n",
    "Параметры задачи обучения:\n",
    "\n",
    "- objective - используемая при обучении функция потерь:\n",
    "\n",
    "\"reg:linear\" – линейная регрессия. \"reg:logistic\" – логистическая регрессия. \"binary:logistic\" – логистическая регрессия для бинарной классификации, на выходе - вероятность. \"binary:logitraw\" – то же самое, но на выходе - значение до его преобразования логистической функцией. \"count:poisson\" – регрессия Пуассона (используется для оценки числа каких-то событий, счётный признак), на выходе - матожидания распределения Пуассона. В этом случае max_delta_step автоматически устанавливается равным 0.7. \"multi:softmax\" – обобщение логистической регрессии на многоклассовый случай. При этом нужно задать параметр num_class. \"multi:softprob\" – то же самое, но на выходе - вектор размера ndata * nclass, который можно преобразовать в матрицу, содержащую вероятности отнесения данного объекта к данному классу. \"rank:pairwise\" – используется для задач ранжирования.\n",
    "\n",
    "- base_score [default=0.5] - инициализация значения модели для всех примеров, глобальное смещение.\n",
    "\n",
    "- eval_metric [default according to objective] - метрика качества на валидационной выборке (по умолчанию соответствует функции потерь: rmse - для регрессии, error - для классификации, mean average precision - для ранжирования). Выбрать можно одну из следующих метрик: \"rmse\": root mean square error. \"logloss\": минус логарифм правдоподобия. \"error\": доля ошибок для бинарной классификации. \"merror\": то же самое для многоклассовой классификации. \"mlogloss\": logloss для многоклассовой классификации. \"auc\": AUC. \"ndcg\": Normalized Discounted Cumulative Gain. \"map\": Mean average precision. \"ndcg@n\",”map@n”: здесь n - целое число, первые n позиций в списке не учитываются. \"ndcg-\",”map-”,”ndcg@n-”,”map@n-”: списку из всех положительных примеров будет присвоено значение 0 (вместо 1).\n",
    "\n",
    "- seed (/random_state) - для воспроизводимости \"случайности\".\n",
    "\n",
    "Эти параметры используются при вызове, например, методов XGBClassifier() и XGBRegressor()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть $X$ --- множество объектов, $Y$ --- множество ответов. Пусть есть обучающая выборка $X^n = (x_i, y_i)_{i=1}^{n},$ $x_i \\in \\mathbb{R}^p$. Обозначим $(x^1,\\ldots,x^p)\\in \\mathbb{R}^p$ --- вектор признаков объекта $x\\in X$. Рассмотрим следующую задачу построения предсказывающей модели:\n",
    "\t\\begin{equation*}\n",
    "\tQ(a, X^n) = \\frac{1}{n} \\sum_{i=1}^{n} \\mathcal{L}(a,x_i,y_i) \\rightarrow \\min_w,\n",
    "\t\\end{equation*}\n",
    "\tгде алгоритм $a$ зададим следующим образом (рассмотрим особый класс функций):\n",
    "\t\\begin{equation*}\n",
    "\ta(x, w) = \\sigma( \\langle w,x \\rangle ) = \\sigma\\left(\\sum_{j=1}^{p} w_j x^j - w_0 \\right),\n",
    "\t\\end{equation*}\n",
    "\tгде $w_k \\in \\mathbb{R}$, $k=0,\\ldots,p$ --- параметры; \n",
    "\t$\\sigma: \\mathbb{R} \\rightarrow  \\mathbb{R} $ --- функция активации;\n",
    "\t$\\mathcal{L}(a,x_i,y_i)$ --- функция потерь, $i=1,\\ldots,n$. Такой класс функций включает в себя, например, линейную классификацию и линейную регрессию.\n",
    "    \n",
    " Возникает вопрос --- насколько богатый класс функций может быть реализован нейроном? \n",
    "\n",
    "Теорема [Цыбенко, 1989]\n",
    "\tПусть $\\sigma(x)$ --- непостоянная, ограниченная и монотонно возрастающая непрерывная функция; $C(I_{p_0})$ --- множество непрерывных функций на $[0,1]^{p_0}$.\n",
    "\t\n",
    "Тогда $\\forall f \\in C(I_{p_0})$ и $\\forall \\varepsilon > 0$  $\\exists ~p_1 \\in \\mathbb{Z}$ и  $\\alpha_i$, $b_i$, $w_{ij} \\in \\mathbb{R}$, $i=1,\\ldots,p_1$, $j=1,\\ldots, p_0$, такие что для любого $x=(x^1, \\ldots, x^{p_0}) \\in I_{p_0}$ выполняется\n",
    "\t$$| F(x^1, \\ldots, x^{p_0}) - f(x^1, \\ldots, x^{p_0})| < \\varepsilon$$,\n",
    "\tгде \n",
    "\t$$F(x^1, \\ldots, x^{p_0})=\\sum_{i=1}^{p_1} \\alpha_i \\, \\sigma \\left(\\sum_{j=1}^{p_0} w_{ij} x^j + b_i   \\right).$$\n",
    "\n",
    "Из этой теоремы можно сделать вывод, что любую непрерывную функцию можно приблизить нейронной сетью с любой желаемой точностью. А также, что для этой сети требуется один скрытый слой и одна нелинейная функция активации. \n",
    "\n",
    "Верно следующее:\n",
    "\n",
    "- Двухслойная сеть в $\\{0,1\\}^n$ позволяет реализовать любую булеву функцию. \n",
    "\n",
    "- Двухслойная сеть в $\\mathbb{R}^n$ позволяет реализовать любой выпуклый многогранник. \n",
    "\n",
    "- Трехслойная сеть в $\\mathbb{R}^n$ позволяет отделить любую многогранную область, не обязательно выпуклую и не обязательно связную. \n",
    "\n",
    "- С помощью линейных операций и одной нелинейной функции активации можно приблизить любую непрерывную функцию с любой точностью. \n",
    "\n",
    "\n",
    "В качестве функций активации чаще всего используются следующие функции:\n",
    "\n",
    "- Сигмоидная функция: $\\sigma(z) = \\frac{1}{1+e^{-a\\,z}}$, $a \\in \\mathbb{R}$;\n",
    "\t\n",
    "- Softmax: $SM_i(z)  = \\frac{e^{z_i}}{\\sum_{k=1}^{K}e^{z_k}}$;\n",
    "\n",
    "- Гиперболический тангенс: $\\sigma(z) = \\frac{e^{a\\,z} - e^{-a\\,z}}{e^{a\\,z} + e^{-a\\,z}}$, $a \\in \\mathbb{R}$;\n",
    "\n",
    "- Выпрямитель: $ReLU(p) = \\max (0,p)$;\n",
    "\n",
    "Последняя чаще всего используется для нейронных сетей с большим количеством слоев.\n",
    "    \n",
    "Возьмем для простоты двухслойную нейронную сеть. Из-за большого количества параметров посчитать градиент в градиентных методах достаточно трудоемко. Для решения этой проблемы используем алгоритм обратного распространения ошибки. Идея состоит в том, чтобы при вычислении сети сохранять некоторые величины, которые впоследствии помогут быстро посчитать градиент. \n",
    "\n",
    "Алгоритм back-propagation.\n",
    "\n",
    "Вход: $\\mathbb{X}^n=\\{x_i, y_i\\}_{i=1}^n$ --- обучающая выборка, $x_i \\in \\mathbb{R}^p$, $y_i \\in \\mathbb{R}^M$, $H$ --- число нейронов на скрытом слое, $\\eta$ --- темп обучения, параметр $\\lambda$\n",
    "\n",
    "Выход: $w_{jh}, w_{hm}$ --- веса\n",
    "\t\n",
    "1. Инициализация весов $w_{jh},~ w_{hm}$;\n",
    "2.\tПовторять, пока $Q$ не сойдется:\n",
    "\n",
    "\ta.\tВыбираем $x_i$ из $\\mathbb{X}^n$;\n",
    "    \n",
    "\tb.\tПрямой ход: \n",
    "    \n",
    "\t\t$$u^h:=\\sigma_h(\\sum\\limits_{j=0}^n w_{jh}x_i^j), ~~~ h=1,\\ldots,H;$$  \n",
    "\t\t$$a^m:=\\sigma_m(\\sum\\limits_{h=0}^H w_{hm}u_i^h),~~ \\varepsilon_i^m:=a_i^m-y_i^m, ~~~ m=1,\\ldots,M;$$     \n",
    "\t\t$$\\mathcal{L}_i:=\\sum\\limits_{m=1}^M (\\varepsilon_i^m)^2;$$\n",
    "        \n",
    "    c. Обратный ход: $$\\varepsilon_i^h:= \\sum\\limits_{m=1}^M \\varepsilon_i^m\\sigma_m' w_{hm}, ~~~ h=1,\\ldots,H;$$\n",
    "    \n",
    "\td. Градиентный шаг: \n",
    "\t\t$$w_{hm}:=w_{hm}-\\eta \\varepsilon_i^m \\sigma_m' u^h(x_i), ~~~~~~ h=0,\\ldots,H, ~ m=1,\\ldots,M;$$      \n",
    "\t\t$$w_{jh}:=w_{jh}-\\eta \\varepsilon_i^h \\sigma_h' f^j(x_i), ~~~~~~ j=0,\\ldots,p, ~ h=1,\\ldots,H;$$ \n",
    "       \n",
    "    e. $Q:=(1-\\lambda)Q+\\lambda\\mathcal{L}_i$;\t\t\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция в python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
